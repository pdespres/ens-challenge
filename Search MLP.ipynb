{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26495, 18124) (26495, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "data_folder = Path('/sgoinfre/goinfre/Perso/pdespres/data/')\n",
    "#data_folder = Path('E:/Downloads/')\n",
    "#data_folder = Path('C:/Users/Paul/Downloads/')\n",
    "#train2_irf_0000_corr98.csv\n",
    "df = pd.read_csv(data_folder/'train_redux2.csv', \\\n",
    "                 dtype='int8')\n",
    "y = pd.read_csv(data_folder/'y2.csv', \\\n",
    "                sep=';', usecols=[1], dtype='int8')\n",
    "\n",
    "print(df.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the AUC is : 0.7068\n",
      "***** 0.7067545215328255 {'dropout3': 0.6, 'units3': 64}\n",
      "the AUC is : 0.8255\n",
      "***** 0.8254998321899373 {'dropout3': 0.6, 'units3': 128}\n",
      "the AUC is : 0.8313\n",
      "***** 0.8313292410265053 {'dropout3': 0.4, 'units3': 128}\n",
      "{'dropout3': 0.4, 'units3': 128}\n",
      "the AUC is : 0.6921\n",
      "the AUC is : 0.8309\n",
      "{'dropout3': 0.6, 'units3': 64}\n",
      "the AUC is : 0.8284\n",
      "the AUC is : 0.8267\n",
      "the AUC is : 0.8317\n",
      "***** 0.8316514682004998 {'dropout3': 0.5, 'units3': 64}\n",
      "{'dropout3': 0.5, 'units3': 64}\n",
      "the AUC is : 0.6263\n",
      "the AUC is : 0.8320\n",
      "***** 0.8320222719716075 {'dropout3': 0.4, 'units3': 64}\n",
      "{'dropout3': 0.4, 'units3': 64}\n",
      "the AUC is : 0.8286\n",
      "the AUC is : 0.8316\n",
      "{'dropout3': 0.6, 'units3': 128}\n",
      "the AUC is : 0.8312\n",
      "{'dropout3': 0.5, 'units3': 128}\n",
      "the AUC is : 0.8322\n",
      "***** 0.8322107144191266 {'dropout3': 0.4, 'units3': 128}\n",
      "{'dropout3': 0.4, 'units3': 128}\n",
      "the AUC is : 0.7127\n",
      "the AUC is : 0.8055\n",
      "the AUC is : 0.8338\n",
      "***** 0.8338361119726037 {'dropout3': 0.4, 'units3': 64}\n",
      "{'dropout3': 0.4, 'units3': 64}\n",
      "the AUC is : 0.8305\n",
      "{'dropout3': 0.5, 'units3': 128}\n",
      "the AUC is : 0.8326\n",
      "{'dropout3': 0.6, 'units3': 128}\n",
      "the AUC is : 0.6920\n",
      "\n",
      "best:\n",
      "the AUC is : 0.8383\n",
      "0.8338361119726037\n",
      "{'dropout3': 0.4, 'units3': 64}\n",
      "\n",
      "\n",
      "CPU times: user 2h 10min 13s, sys: 14min 48s, total: 2h 25min 2s\n",
      "Wall time: 1h 3min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GaussianNoise, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt import space_eval\n",
    "import warnings\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=PendingDeprecationWarning)\n",
    "\n",
    "def Performance(Model,Y,X):\n",
    "    AUC = roc_auc_score(Y, Model.predict_proba(X, verbose=0))\n",
    "    print ('the AUC is : %0.4f' %  AUC)\n",
    "    return AUC\n",
    "\n",
    "def auc_model(params):\n",
    "    clf = xgb.XGBClassifier(**params)\n",
    "    clf.fit(train_x, train_y)\n",
    "    classifier.fit(train_x, train_y, validation_data=(test_x, test_y), shuffle=True, \\\n",
    "               epochs=50, batch_size=100, callbacks=callbacks)\n",
    "    AUC = Performance(clf, test_y, test_x)\n",
    "    return AUC\n",
    "\n",
    "def last_model(params):\n",
    "    mlp = Sequential()\n",
    "    mlp.add(Dense(units=256, kernel_initializer = 'lecun_uniform', \\\n",
    "                  activation='elu', input_dim = train_x.shape[1]))\n",
    "    mlp.add(Dropout(0.25))\n",
    "    mlp.add(Dense(units=256, kernel_initializer = 'lecun_uniform', activation='elu'))\n",
    "    mlp.add(Dense(units=params['units3'], kernel_initializer = 'lecun_uniform', activation='elu'))\n",
    "    mlp.add(Dropout(params['dropout3']))\n",
    "    mlp.add(Dense(units = 1, kernel_initializer = 'lecun_uniform', activation = 'sigmoid'))\n",
    "    mlp.compile(optimizer='adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    mlp.fit(train_x, train_y, validation_data=(test_x, test_y), shuffle=True, \\\n",
    "               epochs=50, batch_size=1024, callbacks=callbacks, verbose=0)\n",
    "    auc = Performance(mlp, valid_y, valid_x)\n",
    "    return mlp, auc\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_acc', patience=3, verbose=0)]\n",
    "                #ModelCheckpoint(filepath='E:\\\\Downloads\\\\best_model_{epoch:02d}-{val_acc:.3f}.h5', \\\n",
    "                #monitor='val_acc', save_best_only=True)]\n",
    "\n",
    "param_space = {\n",
    "    'units3': hp.choice('units3', [64, 128]),\n",
    "    'dropout3': hp.choice('dropout3', [0.4,0.5,0.6])\n",
    "    }\n",
    "\n",
    "def f(params):\n",
    "    global best\n",
    "    global best_params\n",
    "    mlp = Sequential()\n",
    "    mlp.add(Dense(units=256, kernel_initializer = 'lecun_uniform', \\\n",
    "                  activation='elu', input_dim = train_x.shape[1]))\n",
    "    mlp.add(Dropout(0.25))\n",
    "    mlp.add(Dense(units=256, kernel_initializer = 'lecun_uniform', activation='elu'))\n",
    "    mlp.add(Dense(units=params['units3'], kernel_initializer = 'lecun_uniform', activation='elu'))\n",
    "    mlp.add(Dropout(params['dropout3']))\n",
    "    mlp.add(Dense(units = 1, kernel_initializer = 'lecun_uniform', activation = 'sigmoid'))\n",
    "    mlp.compile(optimizer='adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    mlp.fit(train_x, train_y, validation_data=(test_x, test_y), shuffle=True, \\\n",
    "               epochs=50, batch_size=1024, callbacks=callbacks, verbose=0)\n",
    "    auc = Performance(mlp, test_y, test_x)\n",
    "    if auc > best:\n",
    "        best = auc\n",
    "        best_params = params\n",
    "        print('*****', best, params)\n",
    "    if auc > 0.83 and auc > (best - 0.004):\n",
    "        print (params)\n",
    "    return {'loss': -auc, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "s1 = StratifiedShuffleSplit(n_splits=1, test_size=0.20)\n",
    "for t1_index, val_index in s1.split(df, y):\n",
    "    s1_x, s1_y = pd.DataFrame(df.iloc[t1_index]), y.iloc[t1_index].values.ravel()\n",
    "    valid_x, valid_y = df.iloc[val_index], y.iloc[val_index].values.ravel()\n",
    " \n",
    "#cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "cv = StratifiedShuffleSplit(n_splits=1, test_size=0.25)\n",
    "for train_index, test_index in cv.split(s1_x, s1_y):\n",
    "    train_x, train_y = pd.DataFrame(s1_x.iloc[train_index]), s1_y[train_index]\n",
    "    test_x, test_y = pd.DataFrame(s1_x.iloc[test_index]), s1_y[test_index]\n",
    "\n",
    "    trials = Trials()\n",
    "    best = 0\n",
    "    fmin(f, param_space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "    print ('\\nbest:')\n",
    "    model, AUC = last_model(best_params)\n",
    "    print(best)\n",
    "    output = 'MLP_' + str(int(AUC * 10000)) + '.pkl'\n",
    "    #model.save(data_folder/output)\n",
    "    #print(space_eval(param_space, best_params))\n",
    "    print(best_params)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2163713\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_361 (Dense)            (None, 256)               2064896   \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_363 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_364 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,163,713\n",
      "Trainable params: 2,163,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "#0.8245 ENS\n",
    "#0.8468 (0.8496) search 100\n",
    "classifier = load_model(data_folder/'MLP_8468.pkl') \n",
    "t1 = pd.read_csv('E:\\\\Downloads\\\\drop_corr98.csv', names=['a','b'])\n",
    "t1.drop(['b'], axis=1, inplace=True)\n",
    "t1 = t1.drop(t1.index[:1])\n",
    "t2 = pd.read_csv('E:\\\\Downloads\\\\irf_weight_00000.csv', names=['a','b'])\n",
    "t2.drop(['a'], axis=1, inplace=True)\n",
    "t2.columns = ['a']\n",
    "t2 = t2.drop(t2.index[:1])\n",
    "concatenated = pd.concat([t1, t2], axis=0)\n",
    "concatenated.drop_duplicates('a')\n",
    "test = pd.read_csv(data_folder/'test_redux.csv')\n",
    "mlp_test = test.drop(concatenated['a'].tolist(), axis=1)\n",
    "probas_ = classifier.predict_proba(mlp_test)\n",
    "print(classifier.get_config())\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns={'Ids', 'TARGET'})\n",
    "submission['Ids'] = [i for i in range(26500,39750)]\n",
    "submission['TARGET'] = probas_\n",
    "submission = submission[['Ids', 'TARGET']]\n",
    "submission.to_csv(data_folder/'submission.csv', sep=';', index=False, header={'Ids', 'TARGET'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
